# Learning-to-Detect-Heavy-Drinking-Episodes-Using-Smartphone-Accelerometer-Data
## ABSTRACT
Alcohol use in young adults is common, with high rates of morbidity and mortality largely due to periodic, heavy drinking episodes (HDEs). Excessive alcohol consumption is a significant cause of death worldwide and an especially severe risk on college campuses. Recent work aimed at promoting healthier drinking habits has shown promise for the effectiveness of just-in-time adaptive interventions (JITAIs) delivered on mobile platforms just before the onset of heavy drinking episodes. However, delivering well-timed JITAIs is difficult for alcohol-related interventions because accurately detecting the onset of such episodes is challenging. Recent work has explored how smartphone data can be used to classify user drinking behavior, but current methods lack generalizability or make liberal use of private user information. We address these shortcomings to develop a reliable mobile classifier that uses only non-sensitive accelerometer data to detect periods of heavy drinking. Additionally, we examine multiple models and discern a new feature set that increases prediction power by as much as 14%. We used our data set – Bar Crawl: Detecting Heavy Drinking from UCI machine learning repository, where the dataset had smartphone accelerometer readings and transdermal alcohol content (TAC) for 13 subjects participating in an alcohol consumption field study. The TAC readings served as the ground-truth when training the system to make classifications, unlike previous literature which used potentially biased self-reports. Our best classifier detected heavy drinking events with 83.2% accuracy.
## INTRODUCTION TO THE DATA
According to WHO worldwide, 3 million deaths every year result from harmful use of alcohol, this represent 5.3 % of all deaths. According to the 2018 National Survey on Drug Use and Health (NSDUH), 86.3 percent of people ages 18 or older reported that they drank alcohol at some point in their lifetime. Thus, social workers have studied how to reduce heavy drinking habits in college students through interventions such as education programs [Brown-Rice et al., 2015], motivational
feedback [Borsari and Carey, 2000], and social media campaigns [Thompson et al., 2013] to name a few. With the advent of mobile technologies, researchers have recently begun to investigate the effectiveness of mobile interventions. One study showed that weekly mobile-based interventions can be effective in reducing alcohol consumption in students [Suffoletto et al., 2015], suggesting that students are receptive to mobile communication about drinking. However, a recent study which delivered hourly mobile interventions to participants during drinking events showed no significant reduction in the amount of alcohol consumed [Wright et al.,
2018], suggesting that overly frequent messaging can reduce the effectiveness of interventions. This highlights the need for accurate, targeted messages to participants during drinking episodes. The most reliable method for detecting a drinking event is by directly measuring a proxy such as transdermal alcohol content (TAC).
In this work we develop a smartphone-based system to passively track a user’s level of intoxication via accelerometer signals to support the delivery of mobile just-in-time adaptive interventions during heavy drinking events. Smartphone-based solutions are readily scalable since they require no new technological adoption by the user. Further, we ensure that our system minimizes the chance that users will become annoyed or uncomfortable such that they disengage with the system entirely for the following two reasons. First, our system’s passive nature requires no user action beyond their normal behavior to generate measurements. Second, our system uses only raw accelerometer readings rather than highly sensitive user data such as keystrokes, calls, or location. The dataset had smartphone accelerometer data for 13 students participating in a one-day “bar crawl” event where students, as a group, visited all the bars in a certain region on campus. Further, each student wore an ankle bracelet that measured TAC. Thus, the dataset’s findings are 1) applicable to real-world drinking scenarios and 2) our classifications are free from user bias.
Predictive New Features: We adapt frequency domain audio features like spectral centroid spread —traditionally used for audio classification— and apply them to classifying accelerometer data.
Heavy Drinking Classifier: We develop a model that makes
classifications on 10-second windows of accelerometer data to
support the delivery of interventions in real-time. We train several machine learning classifiers including a SGD with a multilayer perceptron model, ADABOOST, Gaussian Naïve Bayes, linear Support Vector Machine with hinge loss and random forest, to make classifications of sober (TAC < 0.08) vs. intoxicated (TAC _ 0.08). The random forest performs the best, achieving an accuracy of 83.2%.
## IMPLEMENTATION DETAILS
### About Data
Accelerometer data was collected from smartphones at a sampling rate of 40Hz. The file contains 5 columns: a timestamp, a participant ID, and a sample from each axis of the accelerometer. The source data was collected from a mix of 11 iPhones and 2 Android phones as noted in phone_types.csv. TAC data was collected using SCRAM ankle bracelets and was collected at 30-minute intervals. The raw TAC readings were
provided in a file for each of the participant. TAC readings which are more readily usable for processing have two columns: a timestamp and TAC reading. The cleaned TAC readings: (1) were processed with a zero-phase low-pass filter to smooth noise without shifting phase; (2) were shifted backwards by 45 minutes so the labels more closely match the true intoxication of the participant (since alcohol takes about 45 minutes to exit through the skin.)
### Data set generation – Moving data to higher dimensions.
Just the given data of the three-dimensional values of x, y, z was not separable by the classifiers to detect if a given person is intoxicated above the level. To be able to classify these values, the data values needed to be transformed into higher dimensions. Given that the input given to us a time domain signal, we performed the operations mentioned in the table given below to generate more features and transform the dataset into higher dimension values. This transformation process was performed for two windows of the given signals, one for a 1 second window and another for a 10 second window. Apart from the time domain signal, we transformed the data into the frequency domain to extract attributes from the frequency domain, the attributes extracted are mentioned in the table found below. Given that each of the x, y and z values are sampled at 40Hz, we transformed the data for each second. To do this we collected the samples measured in each of the attributes and response
Features - 
Mean,
Standard Deviation,
Median,
Variance,
Absolute Min,
Absolute Max,
Root Mean Square,
Energy Entropy,
Energy,
Skew,
Kurtosis,
Variance,
Spectral Centroid.
Features calculated for each sample of accelerometer data. Each of the features described in the first 10 rows are calculated per window, then used again to find the difference between the current and previous window resulting in double the features.
### Dataset generation – Mapping intoxication rates
Now armed with a 76-dimension values for each second, we wanted to map the TAC reading for the individual to each of these seconds. To retrieve the value of the intoxication at a given second, we map the intoxication value as the previous known value of the TAC reading. This way, we are assuming that a person is not intoxicated until the reading is raised above 0.08.
## RESULTS
Using a window length of 10 seconds, we had 369800 rows of data each with 57 features each. Intoxicated samples (TAC > 0.08) accounted for about one-third of the data (86593 samples). We randomized the data according to k-fold cross validation with 10 splits then assign 25% as the test set. We started with multilayer perceptron model which gave us an accuracy of 51.5%. The MLP classification does not work here in this case because Multi-layer perceptron’s have a disadvantage of having to provide fixed number of inputs for producing fixed number of outputs: specifying the temporal dependence upfront in the design of the model. Next, we implemented ADABOOST with average 75% accuracy, though the accuracy of the model was relatively low it was more stable compared to the rest of the models. The disadvantage with AdaBoost was that the number of AdaBoost iterations is also a poorly set number of weak classifiers, which can be determined using cross-validation. Also, training is time consuming, and it is best to cut the point at each reselection of the current classifier. Next, we used Gaussian Naïve Bayes Classifier which provided an accuracy in the range 36 – 72.2%, We found the accuracy of the model to be not stable and heavily dependent on the training samples. Next wen used linear SVM SGD with hinge loss that gave us an average accuracy of 75%. After that we implemented logistic regression SGD classifier with an average accuracy of 76.5%. Finally, we implemented Random forest algorithm which was best among all algorithms with an accuracy of 83.2%. This algorithm performed best because it offers efficient estimates of the test error without incurring the cost of repeated model training associated with cross-validation Initially the number of trees in the random forest classifier were taken 100, but with a smaller number of features. Then the number of trees were increased to 700 to incorporate such large sample size of the dataset.
Algorithm
Accuracy
MLP
51.5%
ADABOOST
61.4% – 82.2%
Gaussian Naïve Bayes
36% – 72.2%
SVM with SGD
75.2%
Logistic Regression
76.5%
Random Forest
83.2%
## FUTURE WORK
Given that the time series signal collects a lot of data we can investigate if neural networks such as LSTM or GRU could be a better fit to solve these problems. Using them once again, we can have two Bidirectional GRU’s one for time domain signal and one for frequency domain signal where at each time stamp, we expect a response from the signal as to whether the person is intoxicated or not. Using them once again, we can have two Bidirectional GRU’s.
## CONCLUSION
We analyzed a high-quality dataset for training a machine learning classifier to differentiate between a sober and intoxicated subject using only tri-axial accelerometer signals. The dataset was more reliable than most studies of its nature, given that ground truth intoxication levels were established using sensors, rather than potentially biased self-reports. Further, on our dataset we achieved the highest accuracy for accelerometer-only binary classification of sobriety, obtaining a test accuracy of 83.2% with a random forest classifier. More work is needed to better understand what differentiates sober from intoxicated accelerometer signals—but these results will serve to improve the baseline for future studies addressing this issue. To support continued research, we plan to make the de-identified accelerometer and transdermal alcohol content.
## REFERENCE
Killian, J.A., Passino, K.M., Nandi, A., Madden, D.R. and Clapp, J., Learning to Detect Heavy Drinking Episodes Using Smartphone Accelerometer Data. In Proceedings of the 4th International Workshop on Knowledge Discovery in Healthcare Data co-located with the 28th International Joint Conference on Artificial Intelligence (IJCAI 2019) (pp. 35-42). [Web Link]
